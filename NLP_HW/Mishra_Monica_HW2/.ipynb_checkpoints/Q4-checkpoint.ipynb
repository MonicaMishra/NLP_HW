{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Summary Evaluation \n",
    "\n",
    "## 4.1 Building Non-Redundancy Scorers\n",
    "## 4.1.1 \n",
    "Train your classifier with the following three features on training data, with summary as\n",
    "input and “non-redundancy” as gold-standard scores, and report evaluation performance on\n",
    "test data. For evaluation, please use metrics of Mean Squared Error (MSE) and Pearson\n",
    "correlation, both calculated between your classifier’s predictions and gold-standard scores of\n",
    "samples in the test data.\n",
    "\n",
    "Each feature implementation worths 3 points, and building classifiers worths 3 points.\n",
    "\n",
    "1. Maximum repetition of unigrams: calculate the frequencies of all unigrams (remove\n",
    "stop words), and use the maximum value as the feature.\n",
    "\n",
    "2. Maximum repetition of bigrams: calculate the frequencies of all bigrams, and use the\n",
    "maximum value as the feature.\n",
    "\n",
    "3. Maximum sentence similarity: each sentence is represented as average of word embeddings,\n",
    "then compute cosine similarity between pairwise sentences, use the maximum\n",
    "similarity as the features. Use word embeddings GoogleNews-vectors-negative300.bin.gz\n",
    "from Word2vechttps://code.google.com/archive/p/word2vec/ as input for each\n",
    "word. Words in a summary that are not covered by Word2vec should be discarded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import nltk\n",
    "import gensim\n",
    "import string\n",
    "import textstat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from collections import Counter\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## read the data\n",
    "train_data = pd.read_csv(\"q4_train_set.csv\")\n",
    "test_data = pd.read_csv(\"q4_test_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    ## get stop words and punc\n",
    "    stop_words = nltk.corpus.stopwords.words(\"english\")\n",
    "    punc = string.punctuation\n",
    "    \n",
    "    ## replace the NA values with 0\n",
    "    data.fillna(0,inplace=True)\n",
    "    data.replace(\"null\", 0, inplace=True)\n",
    "\n",
    "    ## read the data in sentences format with and without stopwords\n",
    "    word_list_summary = {}\n",
    "    word_list_summary_with_stopwords = {}\n",
    "    pattern = \"[\\w\\-]+\"\n",
    "\n",
    "    for i, summary in enumerate(data[\"Summary\"]):\n",
    "        list_of_sentences = nltk.tokenize.sent_tokenize(data[\"Summary\"][i])\n",
    "        word_list_summary[i] = []\n",
    "        word_list_summary_with_stopwords[i] = []\n",
    "        for sentences in list_of_sentences:\n",
    "            sentences = sentences.replace(\"\\t\",\" \").replace(\"\\n\", \" \")\n",
    "            sentences = sentences.replace(\"  \",\" \")\n",
    "            words_in_sentences = [word for word in nltk.tokenize.word_tokenize(sentences) if re.match(pattern,word) and word not in punc and word not in stop_words]\n",
    "            words_in_sentences_with_stopwords = [word.lower() for word in nltk.tokenize.word_tokenize(sentences) if re.match(pattern,word) and word not in punc]\n",
    "            if words_in_sentences != []:\n",
    "                word_list_summary[i].append(words_in_sentences)\n",
    "                word_list_summary_with_stopwords[i].append(words_in_sentences_with_stopwords)\n",
    "    return (word_list_summary, word_list_summary_with_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the preprocessed data\n",
    "train_word_list_summary, train_word_list_summary_with_stopwords = preprocess(train_data)\n",
    "test_word_list_summary, test_word_list_summary_with_stopwords = preprocess(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## model for word2vec conversion\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(r'C:\\Users\\mm199\\NLP\\HW2\\GoogleNews-vectors-negative300.bin', binary=True)  \n",
    "global model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## get the word embedding\n",
    "def word_embedding(list_of_sentences):\n",
    "    global model\n",
    "    dict_word2vec = {}\n",
    "    for index, word_list in enumerate(list_of_sentences):\n",
    "        arr = np.array([0.0 for i in range(0, 300)])\n",
    "        for word in word_list:\n",
    "            try:\n",
    "                arr += model.get_vector(word)\n",
    "            except KeyError:\n",
    "                continue \n",
    "        dict_word2vec[index] = arr / len(word_list)\n",
    "    try:\n",
    "        max_val_cosine = max(np.sort(cosine_similarity(list(dict_word2vec.values())))[:,-2])\n",
    "    except IndexError:\n",
    "        max_val_cosine = 0.0 ## probably only one sentence in the summary hence the redudancy value is low\n",
    "    return (max_val_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prepare the dataset for part 1 with all features\n",
    "def create_df_non_red(word_list_summary):\n",
    "    features = {}\n",
    "    new_features = {}\n",
    "    for num in word_list_summary:\n",
    "        list_of_words = word_list_summary[num]\n",
    "        unigram_words = [i for word in list_of_words for i in word]\n",
    "        max_uni = max(Counter(unigram_words).values())\n",
    "        bi_gram = []\n",
    "        for index, i in enumerate(unigram_words):\n",
    "            if index == len(unigram_words) - 1:\n",
    "                break\n",
    "            bi = unigram_words[index] + \" \" + unigram_words[index+1]\n",
    "            bi_gram.append(bi)  \n",
    "        max_bi = max(Counter(bi_gram).values())\n",
    "        max_val_cosine = word_embedding(list_of_words)\n",
    "        features[num] = {\"max_uni\" : max_uni, \"max_bi\" : max_bi, \"max_val_cosine\" : max_val_cosine}\n",
    "        num_unigrams = len(set(unigram_words))\n",
    "        num_bigrams = len(set(bi_gram))\n",
    "        new_features[num] = {\"num_unigrams\" : num_unigrams, \"num_bigrams\" : num_bigrams}\n",
    "    df_non_red_features = pd.DataFrame(features).T\n",
    "    df_new_non_red_features = pd.concat([df_non_red_features, pd.DataFrame(new_features).T], axis = 1)\n",
    "    return df_new_non_red_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## create df with all the features for non redundancy\n",
    "df_new_non_red_features_train = create_df_non_red(train_word_list_summary) \n",
    "df_new_non_red_features_test = create_df_non_red(test_word_list_summary) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## train the model on training dataset\n",
    "def train_model (X, y):\n",
    "    clf = LinearRegression()\n",
    "    clf.fit(X, y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## get mse and pearson's coeff\n",
    "def get_accuracy(clf, X, y):\n",
    "    pred = clf.predict(X)\n",
    "    mse = mean_squared_error(pred, y)\n",
    "    r_coeff = pearsonr(pred, y)\n",
    "    print (\" MSE : \", mse, \" Pearson's coeff : \", r_coeff)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE and pearson's coeff with three features: \n",
      " MSE :  0.24594064969574916  Pearson's coeff :  (0.6770281804152865, 3.603437070070039e-28)\n"
     ]
    }
   ],
   "source": [
    "## get y label for training\n",
    "y_label_train = train_data[\"Non-Redundancy\"]\n",
    "y_label_train = [float(i) for i in y_label_train]\n",
    "\n",
    "## get results\n",
    "y_label_test = test_data[\"Non-Redundancy\"]\n",
    "y_label_test = [float(i) for i in y_label_test]\n",
    "\n",
    "clf = train_model (df_new_non_red_features_train[[\"max_bi\", \"max_uni\", \"max_val_cosine\"]], y_label_train)\n",
    "\n",
    "print (\"MSE and pearson's coeff with three features: \")\n",
    "get_accuracy (clf, df_new_non_red_features_test[[\"max_bi\", \"max_uni\", \"max_val_cosine\"]], y_label_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4.1.2 \n",
    "Design two new features for this task. Add each feature to the classifier built in 4.1.1, and\n",
    "report MSE and Pearson correlation. You will get 2 bonus points if any of your proposed\n",
    "feature gets better MSE AND Pearson. You will get 4 bonus points if both features improve\n",
    "previous classifier’s performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSE and pearson's coeff with one new feature that is total number of unigrams in each summary: \n",
      " MSE :  0.23378108051889313  Pearson's coeff :  (0.6949437690469922, 3.538334592158559e-30)\n",
      "\n",
      "MSE and pearson's coeff with another new feature that is total number of bigrams in each summary: \n",
      " MSE :  0.23521397491151624  Pearson's coeff :  (0.6925751437462656, 6.647741971187499e-30)\n",
      "\n",
      "MSE and pearson's coeff with two additional features features: \n",
      " MSE :  0.2333698620964361  Pearson's coeff :  (0.6956291624461577, 2.9447800488451285e-30)\n"
     ]
    }
   ],
   "source": [
    "## run with new features\n",
    "clf = train_model (df_new_non_red_features_train[[\"max_bi\", \"max_uni\", \"max_val_cosine\",\"num_unigrams\"]], y_label_train)\n",
    "\n",
    "print (\"\\nMSE and pearson's coeff with one new feature that is total number of unigrams in each summary: \")\n",
    "get_accuracy (clf, df_new_non_red_features_test[[\"max_bi\", \"max_uni\", \"max_val_cosine\",\"num_unigrams\"]], y_label_test)\n",
    "\n",
    "clf = train_model (df_new_non_red_features_train[[\"max_bi\", \"max_uni\", \"max_val_cosine\",\"num_bigrams\"]], y_label_train)\n",
    "\n",
    "print (\"\\nMSE and pearson's coeff with another new feature that is total number of bigrams in each summary: \")\n",
    "get_accuracy (clf, df_new_non_red_features_test[[\"max_bi\", \"max_uni\", \"max_val_cosine\",\"num_bigrams\"]], y_label_test)\n",
    "\n",
    "clf = train_model (df_new_non_red_features_train, y_label_train)\n",
    "\n",
    "print (\"\\nMSE and pearson's coeff with two additional features features: \")\n",
    "get_accuracy (clf, df_new_non_red_features_test, y_label_test)\n",
    "\n",
    "print (\"\\nAccuracy seems to have improved with the new features (individually and combined)\")\n",
    "\n",
    "                                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4.2 Building Fluency Scorers\n",
    "\n",
    "\n",
    "## 4.2.1 \n",
    "Train your classifier with the following three features on training data, with summary as input\n",
    "and “fluency” as gold-standard scores, and report evaluation performance on test data. For\n",
    "evaluation, please use metrics of Mean Squared Error (MSE) and Pearson correlation, both\n",
    "calculated between your classifier’s predictions and gold-standard scores of samples in the\n",
    "test data.\n",
    "\n",
    "Each feature implementation worths 3 points, and building classifiers worths 3 points.\n",
    "1. Total number of repetitive unigrams: count how many unigrams are the same as the\n",
    "previous unigrams. For example, for a summary “The the article talks talks about\n",
    "language understanding”, the value should be 2.\n",
    "\n",
    "2. Total number of repetitive bigrams: count how many bigrams are the same as the\n",
    "previous bigrams. For example, for a summary “The article the article talks about\n",
    "about language understanding”, the value should be 1.\n",
    "\n",
    "3. Minimum Flesch reading-ease score: use tool from https://pypi.org/project/readability/\n",
    "to get readability score for each sentence, and use the minimum value as the feature.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prepare the dataset for part 2\n",
    "def create_df_fluency(dataset, word_list_summary_with_stopwords):\n",
    "    fluency_features = {}\n",
    "    flesch_score_dict = {}\n",
    "    new_features = {}\n",
    "    for index, summary in enumerate(dataset[\"Summary\"]):\n",
    "        flesch_score_dict[index] = textstat.flesch_reading_ease(summary) \n",
    "    for num in word_list_summary_with_stopwords:\n",
    "        list_of_words = word_list_summary_with_stopwords[num]\n",
    "        unigram_words = [i for word in list_of_words for i in word]\n",
    "        uni_rep = 0\n",
    "        pos_uni_rep = 0\n",
    "        bi_rep = 0\n",
    "        pos_bi_rep = 0\n",
    "        bi_gram = []\n",
    "        bi_gram_pos = []\n",
    "        for index, i in enumerate(unigram_words):\n",
    "            if index == len(unigram_words) - 1:\n",
    "                break       \n",
    "            pos_tagged = nltk.pos_tag(unigram_words)     \n",
    "            if unigram_words[index] == unigram_words[index+1]:\n",
    "                uni_rep += 1  \n",
    "            if pos_tagged[index][1] == pos_tagged[index+1][1] :\n",
    "                pos_uni_rep += 1   \n",
    "            bi = unigram_words[index] + \" \" + unigram_words[index+1]\n",
    "            pos_bi = pos_tagged[index][1] + \" \" + pos_tagged[index+1][1]\n",
    "            bi_gram.append(bi)  \n",
    "            bi_gram_pos.append(pos_bi)\n",
    "        for index, i in enumerate(bi_gram):\n",
    "            if index == len(bi_gram) - 1:\n",
    "                break     \n",
    "            if bi_gram[index] == bi_gram[index+1]:\n",
    "                bi_rep += 1\n",
    "            if bi_gram_pos[index] == bi_gram_pos[index+1]:\n",
    "                pos_bi_rep += 1   \n",
    "        fluency_features[num] = {\"uni_rep\" : uni_rep, \"bi_rep\" : bi_rep, \"flesch_score_dict\" : flesch_score_dict[num]}\n",
    "        new_features[num] = {\"pos_uni_rep\" : pos_uni_rep, \"pos_bi_rep\" : pos_bi_rep}\n",
    "\n",
    "    df_fluency_features = pd.DataFrame(fluency_features).T\n",
    "    df_new_fluency_features = pd.concat([df_fluency_features, pd.DataFrame(new_features).T], axis = 1)\n",
    "    return df_new_fluency_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create df with all the features for fluency\n",
    "df_new_fluency_features_train = create_df_fluency(train_data, train_word_list_summary_with_stopwords) \n",
    "df_new_fluency_features_test = create_df_fluency(test_data, test_word_list_summary_with_stopwords) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE and pearson's coeff with three features: \n",
      " MSE :  0.25075492433424956  Pearson's coeff :  (0.2212366148686577, 0.0016425027188746615)\n"
     ]
    }
   ],
   "source": [
    "## get y label for training\n",
    "y_label_train = train_data[\"Fluency\"]\n",
    "y_label_train = [float(i) for i in y_label_train]\n",
    "\n",
    "## get results\n",
    "y_label_test = test_data[\"Fluency\"]\n",
    "y_label_test = [float(i) for i in y_label_test]\n",
    "\n",
    "clf = train_model (df_new_fluency_features_train[[\"uni_rep\", \"bi_rep\", \"flesch_score_dict\"]], y_label_train)\n",
    "\n",
    "print (\"MSE and pearson's coeff with three features: \")\n",
    "get_accuracy (clf, df_new_fluency_features_test[[\"uni_rep\", \"bi_rep\", \"flesch_score_dict\"]], y_label_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.2\n",
    "Design two new features for this task. Add each feature to the classifier built in 4.2.1, and\n",
    "report MSE and Pearson correlation. You will get 2 bonus points if any of your proposed\n",
    "feature gets better MSE AND Pearson. You will get 4 bonus points if both features improve\n",
    "previous classifier’s performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSE and pearson's coeff with one new feature that is total number of pos repetition of unigrams in each summary: \n",
      " MSE :  0.24683437001413627  Pearson's coeff :  (0.2559373168944643, 0.00025426318721765963)\n",
      "\n",
      "MSE and pearson's coeff with another new feature that is total number of pos repetition of bigrams in each summary: \n",
      " MSE :  0.24963642729618507  Pearson's coeff :  (0.23070142556224768, 0.0010140147198971592)\n",
      "\n",
      "MSE and pearson's coeff with two additional features features: \n",
      " MSE :  0.24664295252884258  Pearson's coeff :  (0.25886747745060773, 0.00021451118912109213)\n",
      "\n",
      "Accuracy seems to have improved with the new features (individually and combined)\n"
     ]
    }
   ],
   "source": [
    "## run with new features\n",
    "clf = train_model (df_new_fluency_features_train[[\"uni_rep\", \"bi_rep\", \"flesch_score_dict\",\"pos_uni_rep\"]], y_label_train)\n",
    "\n",
    "print (\"\\nMSE and pearson's coeff with one new feature that is total number of pos repetition of unigrams in each summary: \")\n",
    "get_accuracy (clf, df_new_fluency_features_test[[\"uni_rep\", \"bi_rep\", \"flesch_score_dict\",\"pos_uni_rep\"]], y_label_test)\n",
    "\n",
    "clf = train_model (df_new_fluency_features_train[[\"uni_rep\", \"bi_rep\", \"flesch_score_dict\",\"pos_bi_rep\"]], y_label_train)\n",
    "\n",
    "print (\"\\nMSE and pearson's coeff with another new feature that is total number of pos repetition of bigrams in each summary: \")\n",
    "get_accuracy (clf, df_new_fluency_features_test[[\"uni_rep\", \"bi_rep\", \"flesch_score_dict\",\"pos_bi_rep\"]], y_label_test)\n",
    "\n",
    "clf = train_model (df_new_fluency_features_train, y_label_train)\n",
    "\n",
    "print (\"\\nMSE and pearson's coeff with two additional features features: \")\n",
    "get_accuracy (clf, df_new_fluency_features_test, y_label_test)\n",
    "\n",
    "print (\"\\nAccuracy seems to have improved with the new features (individually and combined)\")\n",
    "                                                   \n",
    "                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
